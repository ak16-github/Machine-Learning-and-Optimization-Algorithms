{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20i190011_IE684_Lab07_Ex3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6KDAa4GeRCP"
      },
      "source": [
        "**Question_1_ Answer:**\r\n",
        "\r\n",
        "Here, the regularized problem of (2) is expressed in the form:  \\\\\r\n",
        "\r\n",
        "\\begin{align}\r\n",
        "\\min_x f_\\lambda (x) = \\min_x \\ \\sum_{n=1}^{N} f_i (x)    \r\n",
        "\\end{align}\r\n",
        "\r\n",
        "Now the appropriate choice of  $f_i(x)$ is given as: \\\\\r\n",
        "\\begin{align}\r\n",
        "f_i(x) = \\frac{1}{2}(A_ix - y_i)^2 + \\frac{\\lambda}{2N} \\ xx^T\r\n",
        "\\end{align}\r\n",
        "Where,\r\n",
        "\\begin{align}\r\n",
        "A_i = i^{th} \\ row \\ of \\ the \\ matrix  \\ A \r\n",
        "\\  \\  \\  \\ ; \\ \\    \\\r\n",
        "y_i = i^{th} \\ value  \\ of  \\ y\r\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hx_28Q2osds_"
      },
      "source": [
        "**Question_2_ Answer:**\r\n",
        "\r\n",
        "The expression for the gradient of $f_i(x)$ is given by:\r\n",
        "\\begin{align}\r\n",
        "g_i(x) = \\nabla_x f_i(x) = (A_i)^T(A_ix-y_i) + \\frac{\\lambda}{N}x \r\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQcDSRi3IDB_"
      },
      "source": [
        "**Question_3: \\\r\n",
        "Consider the dimension where you observed failure in the previous exercise. \\\r\n",
        "Implement the following algorithm (ALG-LAB8) to solve (3):** \\"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnF_CRc-TvCf"
      },
      "source": [
        "#Code for ALG-LAB8\r\n",
        "import numpy as np\r\n",
        "import timeit\r\n",
        "np.random.seed(1000) #for repeatability\r\n",
        "N = 200"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpzt2uM0S4BG"
      },
      "source": [
        "#Now we will define a function which will compute and return the function value \r\n",
        "def evalf(x, d,l):\r\n",
        "  assert type(x) is np.ndarray   \r\n",
        "  fval = 0.0\r\n",
        "  for i in range(N):\r\n",
        "    fval = fval + l/(2*N)*np.matmul(x.T,x) + 0.5 * (np.linalg.norm(np.matmul(A[i],x) - y[i]))**2\r\n",
        "  return (fval)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mn-IClOcWCWp"
      },
      "source": [
        "def evalg(x,d,l):\r\n",
        "  assert type(x) is np.ndarray \r\n",
        "  assert len(x)  == d\r\n",
        "  grad = np.matmul(A[i],x) - y[i]\r\n",
        "  grad = grad * (A[i].T).reshape(np.shape(x)) + (l/N)*x\r\n",
        "  return grad"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnBG16lXzzi6"
      },
      "source": [
        "**3. ANSWER :**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drmZ9yHIxWIH"
      },
      "source": [
        "$\\Large\\textbf{In the previous exercise we observed failure for dimension value d = 10,000.}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENO8mDIZYlgS",
        "outputId": "2e5a1760-7164-434d-f6f8-9371564ba9f5"
      },
      "source": [
        "d = 10000    #Consider the dimension which caused failure in the previous experiment\r\n",
        "my_tol = my_tol= 1e-5\r\n",
        "alpha = 0.9\r\n",
        "rho = 0.5\r\n",
        "gamma = 0.5\r\n",
        "lambda_reg  = 0.1\r\n",
        "eps = np.random.randn(N,1) \r\n",
        "#Create data matrix, label vector\r\n",
        "A = np.random.randn(N,d)\r\n",
        "xorig = np.ones( (d,1) )\r\n",
        "y = np.dot(A,xorig) + eps\r\n",
        "#initialize the optimization variable to be used in the new algo ALG-LAB8\r\n",
        "x = np.zeros((d,1))\r\n",
        "epochs = 20 #initialize the number of rounds needed to process\r\n",
        "t = 1\r\n",
        "arr = np.arange(N) \r\n",
        "start = timeit.default_timer() \r\n",
        "for epoch in range(epochs):\r\n",
        "  np.random.shuffle(arr) \r\n",
        "  for i in np.nditer(arr):\r\n",
        "    x = x - (1/t)*evalg(x,d,lambda_reg)\r\n",
        "    t = t+1\r\n",
        "alglab8time = timeit.default_timer() - start \r\n",
        "x_alglab8 = x\r\n",
        "#print the time taken, ||Ax_alglab8 - y||^2, ||x_alglab8 - xorig||^2\r\n",
        "diff = np.subtract(x_alglab8, xorig)\r\n",
        "print(\"dimension at which failure was observed = d = \", d)\r\n",
        "print(\"Total time for ALG-LAB8:\", alglab8time)\r\n",
        "print(\"L2 norm difference ||Ax* - y||_2^2: \", np.linalg.norm(np.subtract(np.matmul(A, x_alglab8), y))**2)\r\n",
        "print(\"L2 norm difference || x_opt - xorig||_2^2: \", np.linalg.norm(diff)**2)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dimension at which failure was observed = d =  10000\n",
            "Total time for ALG-LAB8: 0.340298569999959\n",
            "L2 norm difference ||Ax* - y||_2^2:  8.723264230027905e+133\n",
            "L2 norm difference || x_opt - xorig||_2^2:  1.0087397021603739e+130\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOT_RvUuH5mX"
      },
      "source": [
        "$\\large\\textbf{Question_4_Answer:}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nei7mZCtgf0q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66a6276f-b1f1-441d-cb15-51446b99e1c6"
      },
      "source": [
        "d = 10000\r\n",
        "lambda_reg = 0.1\r\n",
        "epochs_array = [30,40,50]\r\n",
        "times_array =[]\r\n",
        "X =[]\r\n",
        "\r\n",
        "for ele in epochs_array:\r\n",
        "  x = np.zeros((d,1))\r\n",
        "  t = 1\r\n",
        "  arr = np.arange(N)\r\n",
        "  start = timeit.default_timer()\r\n",
        "  for epoch in range(ele):\r\n",
        "    np.random.shuffle(arr)\r\n",
        "    for i in np.nditer(arr):\r\n",
        "      x = x - (1/t)*evalg(x,d,lambda_reg)\r\n",
        "      t = t+1\r\n",
        "\r\n",
        "  alglab8time = timeit.default_timer() - start\r\n",
        "  times_array.append(alglab8time)\r\n",
        "  X.append(x)\r\n",
        "\r\n",
        "for i in range(len(epochs_array)):\r\n",
        "  print( 'for epoch value = ',(epochs_array[i]) )\r\n",
        "  print( 'Time Taken = ',(times_array[i]))\r\n",
        "  print('||Ax* -y||_2^2 : ',((np.linalg.norm(np.matmul(A,X[i]) - y))**2),\"  and  \",'||x* - x_orig||_2^2 : ',(np.linalg.norm(X[i] - xorig )**2))\r\n",
        "  print()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "for epoch value =  30\n",
            "Time Taken =  0.5098363470001459\n",
            "||Ax* -y||_2^2 :  1.9245204669366806e+137   and   ||x* - x_orig||_2^2 :  1.9222437941142114e+133\n",
            "\n",
            "for epoch value =  40\n",
            "Time Taken =  0.6491660789999969\n",
            "||Ax* -y||_2^2 :  3.180597385006392e+120   and   ||x* - x_orig||_2^2 :  2.732430117591231e+116\n",
            "\n",
            "for epoch value =  50\n",
            "Time Taken =  0.783762169000056\n",
            "||Ax* -y||_2^2 :  3.036812177750214e+118   and   ||x* - x_orig||_2^2 :  2.8339865461462035e+114\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcbLP5fskgU5"
      },
      "source": [
        "**Here from the above output, it is clear that we are getting outputs/solutions for all those values for which we were getting failure in previous exercise by BFGS method and Newton method.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a2viKTPjI6O"
      },
      "source": [
        "$\\large\\textbf{Question_5_Answer:}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbdnCrluK1rY",
        "outputId": "26c34752-174c-411c-9eb8-a3a04e0b9c75"
      },
      "source": [
        "lambda_array = [1000, 100 , 10, 1, 0.1, 10e-2 , 10e-3]\r\n",
        "d= 10000\r\n",
        "epochs = 20\r\n",
        "times_array1 =[]\r\n",
        "X1 =[]\r\n",
        "\r\n",
        "for l in lambda_array:\r\n",
        "  x = np.zeros((d,1))\r\n",
        "  t = 1\r\n",
        "  arr = np.arange(N)\r\n",
        "  start = timeit.default_timer()\r\n",
        "  for epoch in range(epochs):\r\n",
        "    np.random.shuffle(arr)\r\n",
        "    for i in np.nditer(arr):\r\n",
        "      x = x - (1/t)*evalg(x,d,l)\r\n",
        "      t = t+1\r\n",
        "\r\n",
        "  alglab8time = timeit.default_timer() - start\r\n",
        "  times_array1.append(alglab8time)\r\n",
        "  X1.append(x)\r\n",
        "for i in range(len(lambda_array)):\r\n",
        "  print('for lambda = ',(lambda_array[i]) )\r\n",
        "  print('Time Taken  = ',(times_array1[i]))\r\n",
        "  print('||Ax* -y||_2^2 is : ', ((np.linalg.norm(np.matmul(A,X1[i]) - y))**2 ),\"  and  \",'||x* - x_orig||_2^2 : ',(np.linalg.norm(X1[i] - xorig )**2))\r\n",
        "  print()\r\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "for lambda =  1000\n",
            "Time Taken  =  0.33445264800002406\n",
            "||Ax* -y||_2^2 is :  5.623198579837115e+110   and   ||x* - x_orig||_2^2 :  6.399323054054588e+106\n",
            "\n",
            "for lambda =  100\n",
            "Time Taken  =  0.3624256040000091\n",
            "||Ax* -y||_2^2 is :  2.4566049374165045e+122   and   ||x* - x_orig||_2^2 :  2.877767415586526e+118\n",
            "\n",
            "for lambda =  10\n",
            "Time Taken  =  0.3178245260000949\n",
            "||Ax* -y||_2^2 is :  4.859725966879598e+134   and   ||x* - x_orig||_2^2 :  5.562883799963175e+130\n",
            "\n",
            "for lambda =  1\n",
            "Time Taken  =  0.31099695300008534\n",
            "||Ax* -y||_2^2 is :  8.04625984600564e+121   and   ||x* - x_orig||_2^2 :  9.014148286027954e+117\n",
            "\n",
            "for lambda =  0.1\n",
            "Time Taken  =  0.32753804100002526\n",
            "||Ax* -y||_2^2 is :  9.784550172379472e+137   and   ||x* - x_orig||_2^2 :  1.0711491906502942e+134\n",
            "\n",
            "for lambda =  0.1\n",
            "Time Taken  =  0.31243476899999223\n",
            "||Ax* -y||_2^2 is :  4.4739865194847255e+129   and   ||x* - x_orig||_2^2 :  5.176164406063601e+125\n",
            "\n",
            "for lambda =  0.01\n",
            "Time Taken  =  0.3043168180001885\n",
            "||Ax* -y||_2^2 is :  1.3857286331176143e+137   and   ||x* - x_orig||_2^2 :  1.5864059387815954e+133\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jHNNdrdl4xl"
      },
      "source": [
        "**Here from the above output we can see that for each value of $\\lambda$ we  are getting the solution.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jVGaFxujOtS"
      },
      "source": [
        "$\\textbf{Question_6 : Does ALG-LAB8 work for the failure dimension?}$ \\\r\n",
        "$\\Large\\textbf{ANSWER : }$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jG_4PxWSxTM",
        "outputId": "a82402a9-a7c2-48ef-d755-e87174c2aa61"
      },
      "source": [
        "d_array = [10000, 20000, 25000, 50000, 100000, 200000]\r\n",
        "lambda_reg = 0.1\r\n",
        "epochs = 20\r\n",
        "times_array =[]\r\n",
        "X2 =[]\r\n",
        "\r\n",
        "for d in d_array:\r\n",
        "  eps = np.random.randn(N,1)\r\n",
        "  A = np.random.randn(N,d)\r\n",
        "  xorig = np.ones( (d,1) )\r\n",
        "  y = np.dot(A,xorig) + eps\r\n",
        "  x = np.zeros((d,1))\r\n",
        "  t = 1\r\n",
        "  arr = np.arange(N)\r\n",
        "  start = timeit.default_timer()\r\n",
        "  for epoch in range(epochs):\r\n",
        "    np.random.shuffle(arr)\r\n",
        "    for i in np.nditer(arr):\r\n",
        "      x = x - (1/t)*evalg(x,d,lambda_reg)\r\n",
        "      t = t+1\r\n",
        "\r\n",
        "  alglab8time = timeit.default_timer() - start\r\n",
        "  times_array.append(alglab8time)\r\n",
        "  X2.append(x)\r\n",
        "  print('d:', d)\r\n",
        "  print('time taken:', (alglab8time))\r\n",
        "  print('||Ax* -y||^2 : ',((np.linalg.norm(np.matmul(A,x) - y))**2 ),\"  and  \",'||x* - x_orig||_2^2 : ',(np.linalg.norm(x - xorig )**2))\r\n",
        "  print()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "d: 10000\n",
            "time taken: 0.354312587999857\n",
            "||Ax* -y||^2 :  3.672681853770433e+136   and   ||x* - x_orig||_2^2 :  4.261245167950035e+132\n",
            "\n",
            "d: 20000\n",
            "time taken: 0.8074287109998295\n",
            "||Ax* -y||^2 :  3.7870377361915595e+190   and   ||x* - x_orig||_2^2 :  2.1842438315102885e+186\n",
            "\n",
            "d: 25000\n",
            "time taken: 0.9210079960000712\n",
            "||Ax* -y||^2 :  7.797261752059461e+214   and   ||x* - x_orig||_2^2 :  3.557491580165544e+210\n",
            "\n",
            "d: 50000\n",
            "time taken: 2.979138563000106\n",
            "||Ax* -y||^2 :  2.832553143355613e+299   and   ||x* - x_orig||_2^2 :  6.183951877400164e+294\n",
            "\n",
            "d: 100000\n",
            "time taken: 4.9774917820000155\n",
            "||Ax* -y||^2 :  inf   and   ||x* - x_orig||_2^2 :  inf\n",
            "\n",
            "d: 200000\n",
            "time taken: 8.583240648000128\n",
            "||Ax* -y||^2 :  inf   and   ||x* - x_orig||_2^2 :  inf\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n18BfmOtjbp_"
      },
      "source": [
        "**From the above outputs it is obvious that the  ALG-Lab8 work for failure dimensions.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X68sULD4jRTI"
      },
      "source": [
        "$\\large\\textbf{Question_7: Explain your understanding of ALG-LAB8.}$ \\\r\n",
        "$\\large\\textbf{ANSWER:}$\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQ9EuCVUjx7s"
      },
      "source": [
        "**From this Lab, it is clear that, for large dimensions $d$ we are getting solutions by using ALG-LAB8 method. \\\r\n",
        "Whereas in the  previous exercise, For higher dimensions $d$ in Newton and BFGS methods we were not able to find the solutions i.e. we observed failure for higher dimensions.**"
      ]
    }
  ]
}